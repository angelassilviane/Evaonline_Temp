"""
Script SIMPLIFICADO para adicionar eleva√ß√µes ao worldcities.csv.
Usa Open-Elevation API (sem rate limiting) como principal.

Uso:
    python scripts/add_elevation_to_cities_simple.py --batch 9500
"""
import argparse
import csv
import logging
import time
from datetime import datetime
from pathlib import Path
from typing import Optional

import requests

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class ElevationDownloader:
    """Downloader de eleva√ß√µes usando Open-Elevation."""
    
    def __init__(self):
        self.openelevation_url = "https://api.open-elevation.com/api/v1/lookup"
        self.requests_made = 0
        self.errors = 0
        self.delay_seconds = 0.5  # Delay educado entre requisi√ß√µes
    
    def get_elevation(
        self,
        lat: float,
        lon: float,
        location_name: str = ""
    ) -> float:
        """
        Busca eleva√ß√£o usando Open-Elevation API.
        
        Returns:
            Eleva√ß√£o em metros (0.0 se erro)
        """
        try:
            # Fazer requisi√ß√£o
            response = requests.post(
                self.openelevation_url,
                json={"locations": [{"latitude": lat, "longitude": lon}]},
                timeout=30
            )
            response.raise_for_status()
            
            # Extrair eleva√ß√£o
            data = response.json()
            results = data.get("results", [])
            
            if results:
                elevation = results[0].get("elevation", 0.0)
                self.requests_made += 1
                
                # Rate limiting educado
                time.sleep(self.delay_seconds)
                
                return float(elevation)
            
            logger.warning(f"‚ö†Ô∏è Sem dados para {location_name}")
            self.errors += 1
            return 0.0
            
        except requests.exceptions.Timeout:
            logger.error(f"‚ùå Timeout: {location_name}")
            self.errors += 1
            return 0.0
            
        except Exception as e:
            logger.error(f"‚ùå Erro {location_name}: {e}")
            self.errors += 1
            return 0.0


def add_elevation_to_csv(
    input_csv: Path,
    output_csv: Path,
    max_cities: int = 9500,
    skip_existing: bool = False
):
    """
    Adiciona coluna 'elevation' ao CSV de cidades.
    
    Args:
        input_csv: Caminho do CSV de entrada (city, lat, lng, country, sigla)
        output_csv: Caminho do CSV de sa√≠da (adiciona elevation)
        max_cities: N√∫mero m√°ximo de cidades a processar
        skip_existing: Se True, pula cidades j√° processadas (modo continue)
    """
    downloader = ElevationDownloader()
    
    logger.info("üöÄ Iniciando processamento...")
    logger.info(f"üìÇ Input: {input_csv}")
    logger.info(f"üìÅ Output: {output_csv}")
    logger.info(f"üìä Lote: {max_cities} cidades")
    
    # Verificar se output j√° existe (modo continue)
    existing_cities = set()
    
    if skip_existing and output_csv.exists():
        logger.info("üîÑ Modo: Continuar de onde parou")
        logger.info("üìÇ Carregando cidades j√° processadas...")
        
        with open(output_csv, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                key = f"{row['city']}|{row['country']}"
                existing_cities.add(key)
        
        logger.info(f"‚úÖ {len(existing_cities)} cidades j√° processadas")
    else:
        logger.info("üÜï Modo: Novo processamento")
    
    # Modo de abertura do output
    output_mode = 'a' if skip_existing and existing_cities else 'w'
    write_header = output_mode == 'w'
    
    start_time = datetime.now()
    processed = 0
    skipped = 0
    
    with open(input_csv, 'r', encoding='utf-8') as f_in, \
         open(output_csv, output_mode, encoding='utf-8', newline='') as f_out:
        
        reader = csv.DictReader(f_in)
        
        # Campos de sa√≠da
        fieldnames = ['city', 'lat', 'lng', 'country', 'sigla', 'elevation']
        writer = csv.DictWriter(f_out, fieldnames=fieldnames)
        
        if write_header:
            writer.writeheader()
        
        for row in reader:
            # Verificar limite de processamento
            if processed >= max_cities:
                logger.info(f"‚úã Limite de {max_cities} cidades atingido")
                break
            
            city = row['city']
            country = row['country']
            
            # Verificar se j√° foi processada
            key = f"{city}|{country}"
            if key in existing_cities:
                skipped += 1
                continue
            
            # Extrair coordenadas
            try:
                lat = float(row['lat'])
                lon = float(row['lng'])
            except (ValueError, KeyError) as e:
                logger.error(f"‚ùå Coordenadas inv√°lidas: {city}, {country} - {e}")
                continue
            
            # Buscar eleva√ß√£o
            elevation = downloader.get_elevation(lat, lon, f"{city}, {country}")
            
            # Escrever linha com eleva√ß√£o
            output_row = {
                'city': city,
                'lat': lat,
                'lng': lon,
                'country': country,
                'sigla': row['sigla'],
                'elevation': elevation
            }
            writer.writerow(output_row)
            
            processed += 1
            
            # Log de progresso a cada 100 cidades
            if processed % 100 == 0:
                elapsed = (datetime.now() - start_time).total_seconds()
                rate = processed / elapsed if elapsed > 0 else 0
                eta_seconds = (max_cities - processed) / rate if rate > 0 else 0
                eta_minutes = eta_seconds / 60
                
                logger.info(
                    f"‚úÖ {processed}/{max_cities} ({100*processed/max_cities:.1f}%) "
                    f"| Taxa: {rate:.1f} cidades/s "
                    f"| ETA: {eta_minutes:.1f} min "
                    f"| Requisi√ß√µes: {downloader.requests_made}"
                )
    
    # Estat√≠sticas finais
    total_time = (datetime.now() - start_time).total_seconds()
    total_minutes = total_time / 60
    
    logger.info("\n" + "="*60)
    logger.info("üéâ PROCESSAMENTO CONCLU√çDO!")
    logger.info("="*60)
    logger.info(f"Cidades processadas: {processed}")
    logger.info(f"Cidades puladas (j√° existentes): {skipped}")
    logger.info(f"Tempo total: {total_minutes:.1f} minutos")
    
    if total_time > 0:
        avg_rate = processed / total_time
        logger.info(f"Taxa m√©dia: {avg_rate:.2f} cidades/segundo")
    
    logger.info("="*60)
    logger.info("\n" + "="*60)
    logger.info("üìä ESTAT√çSTICAS")
    logger.info("="*60)
    logger.info(f"Total de requisi√ß√µes: {downloader.requests_made}")
    logger.info(f"Erros: {downloader.errors}")
    logger.info("="*60)
    logger.info(f"\nüìÅ Output salvo em: {output_csv}")


def check_progress(output_csv: Path, total_cities: int = 48060):
    """Verifica progresso do processamento."""
    
    if not output_csv.exists():
        logger.info("üìä PROGRESSO")
        logger.info("="*60)
        logger.info("Nenhuma cidade processada ainda.")
        logger.info("="*60)
        return
    
    with open(output_csv, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        processed = sum(1 for _ in reader)
    
    percentage = 100 * processed / total_cities
    remaining = total_cities - processed
    
    logger.info("\n" + "="*60)
    logger.info("üìä PROGRESSO")
    logger.info("="*60)
    logger.info(f"Processadas: {processed:,} / {total_cities:,}")
    logger.info(f"Percentual: {percentage:.2f}%")
    logger.info(f"Restantes: {remaining:,}")
    logger.info("="*60)


def main():
    parser = argparse.ArgumentParser(
        description="Adicionar eleva√ß√µes ao worldcities.csv"
    )
    parser.add_argument(
        '--input',
        type=str,
        default='data/csv/worldcities.csv',
        help='Caminho do CSV de entrada'
    )
    parser.add_argument(
        '--output',
        type=str,
        default='data/csv/worldcities_with_elevation.csv',
        help='Caminho do CSV de sa√≠da'
    )
    parser.add_argument(
        '--batch',
        type=int,
        default=9500,
        help='N√∫mero m√°ximo de cidades a processar (padr√£o: 9500)'
    )
    parser.add_argument(
        '--continue',
        dest='continue_processing',
        action='store_true',
        help='Continuar de onde parou (pula cidades j√° processadas)'
    )
    parser.add_argument(
        '--check-progress',
        action='store_true',
        help='Apenas verificar progresso (n√£o processar)'
    )
    
    args = parser.parse_args()
    
    input_csv = Path(args.input)
    output_csv = Path(args.output)
    
    # Verificar progresso
    if args.check_progress:
        check_progress(output_csv)
        return
    
    # Validar input
    if not input_csv.exists():
        logger.error(f"‚ùå Arquivo n√£o encontrado: {input_csv}")
        return
    
    # Processar
    add_elevation_to_csv(
        input_csv=input_csv,
        output_csv=output_csv,
        max_cities=args.batch,
        skip_existing=args.continue_processing
    )


if __name__ == "__main__":
    main()
