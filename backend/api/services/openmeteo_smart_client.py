"""
OpenMeteo Smart Client - Intelligent API Router

This client automatically selects the best API based on the requested date range:
- Archive API: 1940-01-01 until (TODAY - 2 days) - 85+ years of history
- Forecast API: (TODAY - 90d) until (TODAY + 16d) - Recent + future data
- Never uses deprecated Historical API (2016-2025 only)

Features:
- Auto-selects Archive vs Forecast API based on date range
- Handles hybrid requests (both APIs if needed)
- Consolidates responses into unified format
- Includes elevation, timezone, and all climate data
- Smart caching (30 days for archive, 6 hours for forecast)
- Comprehensive error handling

Author: AI Assistant
Date: October 23, 2025
Status: Production-Ready
"""

import logging
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Tuple

import openmeteo_requests
import pandas as pd
import requests_cache
from retry_requests import retry

logger = logging.getLogger(__name__)


class OpenMeteoSmartConfig:
    """Configuration for Open-Meteo Smart Client."""
    
    # URLs
    ARCHIVE_API = "https://archive-api.open-meteo.com/v1/archive"
    FORECAST_API = "https://api.open-meteo.com/v1/forecast"
    
    # Timeline constraints
    MIN_DATE = datetime(1940, 1, 1)  # Archive starts here
    ARCHIVE_CUTOFF_DAYS = 2  # Archive has data until TODAY - 2
    FORECAST_MAX_FUTURE = 16  # Forecast goes up to +16 days
    FORECAST_MAX_PAST = 90  # Forecast can go back 90 days
    
    # Date range constraints for users
    MIN_RANGE_DAYS = 7
    MAX_RANGE_DAYS = 30
    
    # Cache TTL
    ARCHIVE_CACHE_TTL = 86400 * 30  # 30 days (data never changes)
    FORECAST_CACHE_TTL = 3600 * 6   # 6 hours (updates daily)
    
    # Climate variables (ORDER MATTERS!)
    DAILY_VARIABLES = [
        "temperature_2m_max",
        "temperature_2m_min",
        "temperature_2m_mean",
        "precipitation_sum",
        "wind_speed_10m_max",
        "wind_speed_10m_mean",
        "shortwave_radiation_sum",
        "relative_humidity_2m_max",
        "relative_humidity_2m_mean",
        "relative_humidity_2m_min",
        "daylight_duration",
        "sunshine_duration",
        "et0_fao_evapotranspiration",  # ET0 FAO-56 pre-calculated
    ]
    
    # Network settings
    TIMEOUT = 30
    RETRY_ATTEMPTS = 5
    BACKOFF_FACTOR = 0.2


class OpenMeteoSmartClient:
    """
    Smart client that automatically selects best API based on date range.
    
    Handles:
    - Historical data: Archive API (1940-2025)
    - Recent/Future: Forecast API (90d back + 16d forward)
    - Hybrid: Both APIs for spanning requests
    
    Response Format (unified regardless of API used):
    {
        "location": {
            "latitude": float,
            "longitude": float,
            "elevation": float,
            "timezone": str,
            "timezone_abbreviation": str,
            "utc_offset_seconds": int,
        },
        "climate_data": {
            "dates": [datetime, ...],
            "temperature_2m_max": [float, ...],
            "temperature_2m_min": [float, ...],
            ...
        },
        "metadata": {
            "api_used": "archive" | "forecast" | "hybrid",
            "api_calls": int,
            "cache_hits": int,
            "total_latency_ms": float,
            "data_points": int,
            "models_available": [str, ...]
        }
    }
    """
    
    def __init__(self, cache_dir: str = ".cache"):
        """
        Initialize OpenMeteo Smart Client with caching and retry logic.
        
        Args:
            cache_dir: Directory for requests_cache
        """
        self.config = OpenMeteoSmartConfig()
        self._setup_client(cache_dir)
        logger.info("‚úÖ OpenMeteoSmartClient initialized")
    
    def _setup_client(self, cache_dir: str):
        """Setup requests cache and retry session."""
        cache_session = requests_cache.CachedSession(
            cache_dir,
            expire_after=-1  # Don't auto-expire, we control TTL
        )
        retry_session = retry(
            cache_session,
            retries=self.config.RETRY_ATTEMPTS,
            backoff_factor=self.config.BACKOFF_FACTOR
        )
        self.client = openmeteo_requests.Client(session=retry_session)
        logger.info(f"‚úÖ Cache dir: {cache_dir}")
    
    async def get_climate_data(
        self,
        lat: float,
        lng: float,
        start_date: str,
        end_date: str,
    ) -> Dict[str, Any]:
        """
        Main entry point: Get climate data with smart API selection.
        
        Args:
            lat: Latitude (-90 to 90)
            lng: Longitude (-180 to 180)
            start_date: Start date (YYYY-MM-DD)
            end_date: End date (YYYY-MM-DD)
        
        Returns:
            Unified response with location, climate data, and metadata
        
        Raises:
            ValueError: Invalid inputs or date range
        """
        import time
        start_time = time.time()
        
        try:
            # 1. Validate inputs
            self._validate_inputs(lat, lng, start_date, end_date)
            
            # 2. Calculate decision parameters
            today = datetime.now().date()
            archive_cutoff = today - timedelta(days=self.config.ARCHIVE_CUTOFF_DAYS)
            forecast_horizon = today + timedelta(days=self.config.FORECAST_MAX_FUTURE)
            
            start = datetime.fromisoformat(start_date).date()
            end = datetime.fromisoformat(end_date).date()
            
            logger.info(
                f"üîç Request: {start_date} to {end_date} | "
                f"Cutoff: {archive_cutoff}, Horizon: {forecast_horizon}"
            )
            
            # 3. Decide which API(s) to use
            api_strategy = self._decide_api_strategy(
                start, end, archive_cutoff, forecast_horizon
            )
            logger.info(f"üìä Strategy: {api_strategy}")
            
            # 4. Fetch data based on strategy
            if api_strategy == "archive_only":
                response = await self._fetch_archive_only(lat, lng, start_date, end_date)
            
            elif api_strategy == "forecast_only":
                response = await self._fetch_forecast_only(lat, lng, start_date, end_date)
            
            elif api_strategy == "hybrid":
                response = await self._fetch_hybrid(
                    lat, lng, start_date, end_date, archive_cutoff
                )
            
            else:
                raise ValueError(f"Invalid strategy: {api_strategy}")
            
            # 5. Add timing metadata
            elapsed = (time.time() - start_time) * 1000  # ms
            response["metadata"]["total_latency_ms"] = round(elapsed, 2)
            
            logger.info(
                f"‚úÖ Complete: {api_strategy} | "
                f"{response['metadata']['data_points']} points | "
                f"{elapsed:.0f}ms"
            )
            
            return response
        
        except Exception as e:
            logger.error(f"‚ùå Error: {str(e)}")
            raise
    
    def _validate_inputs(self, lat: float, lng: float, start_date: str, end_date: str):
        """
        Validate coordinate and date range inputs.
        
        Raises:
            ValueError: Invalid inputs
        """
        # Coordinates
        if not -90 <= lat <= 90:
            raise ValueError(f"Invalid latitude: {lat}. Must be -90 to 90")
        if not -180 <= lng <= 180:
            raise ValueError(f"Invalid longitude: {lng}. Must be -180 to 180")
        
        # Date format
        try:
            start = datetime.fromisoformat(start_date)
            end = datetime.fromisoformat(end_date)
        except ValueError:
            raise ValueError("Dates must be in YYYY-MM-DD format")
        
        # Date logic
        if start > end:
            raise ValueError("start_date must be <= end_date")
        
        if start.date() < self.config.MIN_DATE.date():
            raise ValueError(f"start_date must be >= {self.config.MIN_DATE.date()}")
        
        # Range
        range_days = (end - start).days + 1
        if range_days < self.config.MIN_RANGE_DAYS:
            raise ValueError(f"Range must be >= {self.config.MIN_RANGE_DAYS} days")
        if range_days > self.config.MAX_RANGE_DAYS:
            raise ValueError(f"Range must be <= {self.config.MAX_RANGE_DAYS} days")
    
    def _decide_api_strategy(
        self,
        start: datetime.date,
        end: datetime.date,
        archive_cutoff: datetime.date,
        forecast_horizon: datetime.date,
    ) -> str:
        """
        Determine which API(s) to use.
        
        Decision Tree:
        - If end <= archive_cutoff: Archive only
        - If start <= archive_cutoff < end: Hybrid (both)
        - If archive_cutoff < start and end <= horizon: Forecast only
        - Otherwise: Error (beyond horizon)
        
        Returns:
            "archive_only" | "forecast_only" | "hybrid"
        
        Raises:
            ValueError: Beyond forecast horizon or invalid range
        """
        
        if end <= archive_cutoff:
            # Pure historical data
            logger.info(f"üìö Pure historical: {start} to {end}")
            return "archive_only"
        
        elif start > forecast_horizon:
            # Beyond forecast horizon
            raise ValueError(
                f"end_date cannot exceed {forecast_horizon} "
                f"(forecast horizon is +{self.config.FORECAST_MAX_FUTURE} days)"
            )
        
        elif start <= archive_cutoff < end:
            # Need both APIs
            logger.info(
                f"üîÄ Hybrid: Archive ({start} to {archive_cutoff}) + "
                f"Forecast ({archive_cutoff + timedelta(days=1)} to {end})"
            )
            return "hybrid"
        
        else:
            # Recent/current/future data
            logger.info(f"üîÆ Recent/Forecast: {start} to {end}")
            return "forecast_only"
    
    async def _fetch_archive_only(
        self,
        lat: float,
        lng: float,
        start_date: str,
        end_date: str
    ) -> Dict[str, Any]:
        """
        Fetch from Archive API (historical data only).
        
        Args:
            lat: Latitude
            lng: Longitude
            start_date: Start date (YYYY-MM-DD)
            end_date: End date (YYYY-MM-DD)
        
        Returns:
            Unified response structure
        """
        logger.info(f"üìö Fetching Archive: {start_date} to {end_date}")
        
        params = {
            "latitude": lat,
            "longitude": lng,
            "start_date": start_date,
            "end_date": end_date,
            "daily": self.config.DAILY_VARIABLES,
            "models": "best_match",
            "timezone": "auto",
            "wind_speed_unit": "ms",
        }
        
        # Fetch
        responses = self.client.weather_api(self.config.ARCHIVE_API, params=params)
        response = responses[0]
        
        # Parse response
        return self._parse_response(response, "archive")
    
    async def _fetch_forecast_only(
        self,
        lat: float,
        lng: float,
        start_date: str,
        end_date: str
    ) -> Dict[str, Any]:
        """
        Fetch from Forecast API (recent/current/future data).
        
        Args:
            lat: Latitude
            lng: Longitude
            start_date: Start date (YYYY-MM-DD)
            end_date: End date (YYYY-MM-DD)
        
        Returns:
            Unified response structure
        """
        logger.info(f"üîÆ Fetching Forecast: {start_date} to {end_date}")
        
        # Calculate past_days and forecast_days
        today = datetime.now().date()
        start = datetime.fromisoformat(start_date).date()
        end = datetime.fromisoformat(end_date).date()
        
        past_days = max(0, (today - start).days)
        forecast_days = max(1, (end - today).days + 1)
        
        # Constrain to API limits
        past_days = min(past_days, self.config.FORECAST_MAX_PAST)
        forecast_days = min(forecast_days, self.config.FORECAST_MAX_FUTURE)
        
        logger.info(f"  past_days={past_days}, forecast_days={forecast_days}")
        
        params = {
            "latitude": lat,
            "longitude": lng,
            "past_days": past_days,
            "forecast_days": forecast_days,
            "daily": self.config.DAILY_VARIABLES,
            "models": "best_match",
            "timezone": "auto",
            "wind_speed_unit": "ms",
        }
        
        # Fetch
        responses = self.client.weather_api(self.config.FORECAST_API, params=params)
        response = responses[0]
        
        # Parse response
        return self._parse_response(response, "forecast")
    
    async def _fetch_hybrid(
        self,
        lat: float,
        lng: float,
        start_date: str,
        end_date: str,
        cutoff: datetime.date
    ) -> Dict[str, Any]:
        """
        Fetch from both APIs and merge results.
        
        Splits request into:
        - Archive: start_date to cutoff
        - Forecast: cutoff+1 to end_date
        
        Then merges chronologically.
        
        Args:
            lat: Latitude
            lng: Longitude
            start_date: Start date (YYYY-MM-DD)
            end_date: End date (YYYY-MM-DD)
            cutoff: Archive/Forecast cutoff date
        
        Returns:
            Unified response with merged data
        """
        logger.info(f"üîÄ Fetching Hybrid: Archive + Forecast")
        
        # Archive part
        cutoff_str = cutoff.isoformat()
        archive_response = await self._fetch_archive_only(
            lat, lng, start_date, cutoff_str
        )
        
        # Forecast part
        forecast_start = (cutoff + timedelta(days=1)).isoformat()
        forecast_response = await self._fetch_forecast_only(
            lat, lng, forecast_start, end_date
        )
        
        # Merge
        return self._merge_responses(archive_response, forecast_response)
    
    def _parse_response(
        self,
        response: Any,
        api_type: str
    ) -> Dict[str, Any]:
        """
        Parse Open-Meteo response into unified format.
        
        Args:
            response: Open-Meteo API response
            api_type: "archive" or "forecast"
        
        Returns:
            Unified response structure
        """
        logger.info(f"üîç Parsing {api_type} response...")
        
        # Location data
        location = {
            "latitude": float(response.Latitude()),
            "longitude": float(response.Longitude()),
            "elevation": float(response.Elevation()),
            "timezone": response.Timezone(),
            "timezone_abbreviation": response.TimezoneAbbreviation(),
            "utc_offset_seconds": int(response.UtcOffsetSeconds()),
        }
        
        # Daily data
        daily = response.Daily()
        
        # Build date range
        date_range = pd.date_range(
            start=pd.to_datetime(daily.Time(), unit="s", utc=True),
            end=pd.to_datetime(daily.TimeEnd(), unit="s", utc=True),
            freq=pd.Timedelta(seconds=daily.Interval()),
            inclusive="left"
        )
        
        # Extract each variable
        climate_data = {"dates": date_range.tolist()}
        
        for idx, var in enumerate(self.config.DAILY_VARIABLES):
            values = daily.Variables(idx).ValuesAsNumpy()
            climate_data[var] = values.tolist()
        
        # Metadata
        metadata = {
            "api_used": api_type,
            "api_calls": 1,
            "cache_hits": 0,  # TODO: Track from session
            "data_points": len(date_range),
            "models_available": [response.Models()] if hasattr(response, 'Models') else []
        }
        
        logger.info(f"  ‚úÖ Parsed {len(date_range)} data points")
        
        return {
            "location": location,
            "climate_data": climate_data,
            "metadata": metadata
        }
    
    def _merge_responses(
        self,
        archive_response: Dict[str, Any],
        forecast_response: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Merge archive and forecast responses chronologically.
        
        Args:
            archive_response: Response from Archive API
            forecast_response: Response from Forecast API
        
        Returns:
            Merged unified response
        """
        logger.info("üîÄ Merging archive + forecast responses...")
        
        # Use archive location (both should be identical)
        location = archive_response["location"]
        
        # Merge climate data
        archive_climate = archive_response["climate_data"]
        forecast_climate = forecast_response["climate_data"]
        
        # Convert to DataFrames for easier merging
        df_archive = pd.DataFrame(archive_climate)
        df_forecast = pd.DataFrame(forecast_climate)
        
        # Combine (forecast data after archive)
        df_merged = pd.concat([df_archive, df_forecast], ignore_index=True)
        
        # Convert back to dict
        climate_data = df_merged.to_dict(orient='list')
        
        # Metadata
        metadata = {
            "api_used": "hybrid",
            "api_calls": 2,
            "cache_hits": 0,
            "data_points": len(df_merged),
            "models_available": location.get("models_available", [])
        }
        
        logger.info(f"  ‚úÖ Merged {len(df_merged)} data points (archive + forecast)")
        
        return {
            "location": location,
            "climate_data": climate_data,
            "metadata": metadata
        }
    
    async def close(self):
        """Close HTTP connections."""
        if hasattr(self.client, 'close'):
            await self.client.close()
            logger.info("‚úÖ Client closed")


# Convenience async function for non-class usage
async def get_climate_data_smart(
    lat: float,
    lng: float,
    start_date: str,
    end_date: str,
    cache_dir: str = ".cache"
) -> Dict[str, Any]:
    """
    Convenience function for getting climate data with smart API selection.
    
    Args:
        lat: Latitude
        lng: Longitude
        start_date: Start date (YYYY-MM-DD)
        end_date: End date (YYYY-MM-DD)
        cache_dir: Cache directory
    
    Returns:
        Unified response with location, climate data, and metadata
    """
    client = OpenMeteoSmartClient(cache_dir=cache_dir)
    try:
        return await client.get_climate_data(lat, lng, start_date, end_date)
    finally:
        await client.close()
