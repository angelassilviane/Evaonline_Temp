# Plano: Base de Dados Mundial de Localiza√ß√µes para ETo em Tempo Real

## üéØ Objetivo Corrigido

Criar uma base de dados persistente (PostgreSQL) com localiza√ß√µes das principais cidades do mundo contendo:
- ‚úÖ **Latitude** (float)
- ‚úÖ **Longitude** (float)
- ‚úÖ **Eleva√ß√£o** (float, em metros)
- ‚úÖ **Timezone** (string, ex: "GMT+9.0")
- ‚úÖ **Data Source** (string, ex: "Data Fusion", "NASA POWER")

**ETo √© calculado em tempo real** (n√£o armazenado) usando:
- Dados clim√°ticos atuais (APIs: NASA POWER, MET Norway, NWS USA)
- Fus√£o de dados quando m√∫ltiplas fontes dispon√≠veis
- Localiza√ß√£o (lat, lon, eleva√ß√£o) do PostgreSQL

**Resultado**: 
- ‚úÖ Reduzir requisi√ß√µes de eleva√ß√£o √† Open-Meteo em ~95%
- ‚úÖ ETo sempre dispon√≠vel no mapa (calculado on-demand)
- ‚úÖ Marcadores visuais com ETo em tempo real

---

## üìä Estrutura de Dados Simplificada

### Tabela: `world_locations`

```sql
CREATE TABLE world_locations (
    id SERIAL PRIMARY KEY,
    
    -- Identifica√ß√£o
    location_name VARCHAR(255) NOT NULL,  -- "Nagoya, Aichi, JPN"
    city VARCHAR(100),                    -- "Nagoya"
    region VARCHAR(100),                  -- "Aichi"
    country VARCHAR(100) NOT NULL,        -- "Japan"
    country_code CHAR(3) NOT NULL,        -- "JPN"
    
    -- Coordenadas geogr√°ficas (dados est√°ticos)
    latitude FLOAT NOT NULL,              -- 35.2
    longitude FLOAT NOT NULL,             -- 137.0
    
    -- Eleva√ß√£o (dados est√°ticos - Open-Meteo)
    elevation_m FLOAT NOT NULL,           -- 51.0
    
    -- Timezone (dados est√°ticos)
    timezone VARCHAR(50),                 -- "GMT+9.0" ou "Asia/Tokyo"
    
    -- Fonte de dados clim√°ticos preferencial
    preferred_climate_source VARCHAR(50), -- "Data Fusion", "NASA POWER", etc.
    
    -- Controle
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    -- √çndices para performance
    CONSTRAINT unique_coordinates UNIQUE (latitude, longitude)
);

-- √çndices geoespaciais
CREATE INDEX idx_world_locations_coords ON world_locations (latitude, longitude);
CREATE INDEX idx_world_locations_country ON world_locations (country_code);
```

**‚ö†Ô∏è IMPORTANTE**: 
- **ETo N√ÉO √© armazenado** na tabela
- **ETo √© calculado em tempo real** quando o marcador √© clicado
- Apenas dados geogr√°ficos est√°ticos s√£o armazenados

---

## ü§ñ Script de Coleta Autom√°tica de Dados

### Fase 1: Script Python para Baixar Eleva√ß√µes (2-3 dias)

**Objetivo**: Baixar automaticamente lat, lon, eleva√ß√£o das principais cidades do mundo usando Open-Meteo Elevation API.

**Limites Open-Meteo**:
```
‚úÖ 10.000 chamadas/dia
‚úÖ 5.000 chamadas/hora
‚úÖ 600 chamadas/minuto
```

**Estrat√©gia**: Baixar ~5000 cidades em 1 dia com rate limiting inteligente.

#### Script: `scripts/download_world_elevations.py`

```python
"""
Script para baixar eleva√ß√µes das principais cidades do mundo.
Usa Open-Meteo Elevation API com rate limiting respeitando os termos.
"""
import time
import csv
import requests
from typing import List, Dict
from pathlib import Path
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ElevationDownloader:
    """
    Baixa eleva√ß√µes de cidades usando Open-Meteo API com rate limiting.
    
    Rate Limits Open-Meteo (n√£o-comercial):
    - 10,000 requests/day
    - 5,000 requests/hour
    - 600 requests/minute
    """
    
    def __init__(self):
        self.api_url = "https://api.open-meteo.com/v1/elevation"
        self.requests_made = 0
        self.requests_limit_per_day = 9500  # Margem de seguran√ßa
        self.delay_seconds = 0.15  # 6-7 req/s = 400/min (seguro)
    
    def get_elevation(self, lat: float, lon: float) -> float:
        """
        Busca eleva√ß√£o para coordenadas.
        
        Args:
            lat: Latitude
            lon: Longitude
            
        Returns:
            Eleva√ß√£o em metros (float)
        """
        try:
            response = requests.get(
                self.api_url,
                params={"latitude": lat, "longitude": lon},
                timeout=10
            )
            response.raise_for_status()
            
            data = response.json()
            elevation = data.get("elevation", [None])[0]
            
            if elevation is None:
                logger.warning(f"No elevation data for {lat}, {lon}")
                return 0.0
            
            self.requests_made += 1
            
            # Rate limiting: aguardar entre requisi√ß√µes
            time.sleep(self.delay_seconds)
            
            return float(elevation)
            
        except Exception as e:
            logger.error(f"Error fetching elevation for {lat}, {lon}: {e}")
            return 0.0
    
    def download_from_cities_list(
        self,
        input_csv: str,
        output_csv: str,
        max_cities: int = 5000
    ):
        """
        Baixa eleva√ß√µes de uma lista de cidades.
        
        Input CSV deve ter colunas: location_name, city, country, country_code, latitude, longitude
        Output CSV ter√°: todas as colunas acima + elevation_m, timezone
        
        Args:
            input_csv: Caminho do CSV de entrada (sem eleva√ß√£o)
            output_csv: Caminho do CSV de sa√≠da (com eleva√ß√£o)
            max_cities: N√∫mero m√°ximo de cidades a processar
        """
        processed = 0
        
        with open(input_csv, 'r', encoding='utf-8') as f_in, \
             open(output_csv, 'w', encoding='utf-8', newline='') as f_out:
            
            reader = csv.DictReader(f_in)
            
            # Campos de sa√≠da
            fieldnames = reader.fieldnames + ['elevation_m', 'timezone']
            writer = csv.DictWriter(f_out, fieldnames=fieldnames)
            writer.writeheader()
            
            for row in reader:
                if processed >= max_cities:
                    logger.info(f"Reached max cities limit: {max_cities}")
                    break
                
                if self.requests_made >= self.requests_limit_per_day:
                    logger.warning("Daily rate limit reached!")
                    break
                
                lat = float(row['latitude'])
                lon = float(row['longitude'])
                
                # Buscar eleva√ß√£o
                elevation = self.get_elevation(lat, lon)
                
                # Adicionar dados
                row['elevation_m'] = elevation
                row['timezone'] = self.estimate_timezone(lon)  # Aproximado
                
                writer.writerow(row)
                processed += 1
                
                if processed % 100 == 0:
                    logger.info(
                        f"‚úÖ Processed {processed} cities "
                        f"({self.requests_made} requests made)"
                    )
        
        logger.info(f"üéâ Done! Processed {processed} cities")
        logger.info(f"üìä Total requests: {self.requests_made}")
    
    def estimate_timezone(self, longitude: float) -> str:
        """
        Estima timezone baseado na longitude (aproximado).
        Para timezone preciso, usar API como timezonefinder.
        
        Args:
            longitude: Longitude (-180 a 180)
            
        Returns:
            Timezone string (ex: "GMT+9.0")
        """
        # Cada 15¬∞ de longitude ‚âà 1 hora de diferen√ßa
        offset_hours = round(longitude / 15)
        
        if offset_hours >= 0:
            return f"GMT+{offset_hours}.0"
        else:
            return f"GMT{offset_hours}.0"


def create_cities_input_csv(output_path: str):
    """
    Cria CSV de entrada com principais cidades do mundo.
    
    Fonte sugerida: 
    - Natural Earth Data: https://www.naturalearthdata.com/downloads/10m-cultural-vectors/
    - SimpleMaps: https://simplemaps.com/data/world-cities (Free version: 41k cities)
    - GeoNames: http://download.geonames.org/export/dump/ (cities15000.txt)
    
    Para este exemplo, vou criar um CSV de amostra.
    """
    sample_cities = [
        {
            "location_name": "Tokyo, Kanto, JPN",
            "city": "Tokyo",
            "region": "Kanto",
            "country": "Japan",
            "country_code": "JPN",
            "latitude": 35.6762,
            "longitude": 139.6503
        },
        {
            "location_name": "New York, NY, USA",
            "city": "New York",
            "region": "New York",
            "country": "United States",
            "country_code": "USA",
            "latitude": 40.7128,
            "longitude": -74.0060
        },
        {
            "location_name": "S√£o Paulo, SP, BRA",
            "city": "S√£o Paulo",
            "region": "S√£o Paulo",
            "country": "Brazil",
            "country_code": "BRA",
            "latitude": -23.5505,
            "longitude": -46.6333
        },
        # Adicionar mais cidades aqui...
    ]
    
    with open(output_path, 'w', encoding='utf-8', newline='') as f:
        fieldnames = [
            "location_name", "city", "region", "country",
            "country_code", "latitude", "longitude"
        ]
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(sample_cities)
    
    logger.info(f"‚úÖ Created sample cities CSV: {output_path}")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(
        description='Download elevations for world cities'
    )
    parser.add_argument(
        '--input',
        default='data/cities_input.csv',
        help='Input CSV with cities (without elevation)'
    )
    parser.add_argument(
        '--output',
        default='data/cities_with_elevation.csv',
        help='Output CSV with cities (with elevation)'
    )
    parser.add_argument(
        '--max-cities',
        type=int,
        default=5000,
        help='Maximum number of cities to process'
    )
    parser.add_argument(
        '--create-sample',
        action='store_true',
        help='Create sample input CSV'
    )
    
    args = parser.parse_args()
    
    if args.create_sample:
        create_cities_input_csv(args.input)
    
    downloader = ElevationDownloader()
    downloader.download_from_cities_list(
        args.input,
        args.output,
        args.max_cities
    )
```

**Uso:**

```bash
# 1. Criar CSV de amostra
python scripts/download_world_elevations.py --create-sample

# 2. Baixar eleva√ß√µes (5000 cidades ‚âà 12-15 minutos)
python scripts/download_world_elevations.py \
    --input data/cities_input.csv \
    --output data/cities_with_elevation.csv \
    --max-cities 5000

# 3. Importar para PostgreSQL
python backend/database/scripts/import_world_locations.py \
    data/cities_with_elevation.csv
```

**Estimativa de Tempo**:
```
5000 cidades √ó 0.15s delay = 750 segundos = ~12-15 minutos
```

---

## üó∫Ô∏è Fontes de Dados de Cidades (Input)

### Op√ß√£o 1: SimpleMaps World Cities (Recomendado)
- **URL**: https://simplemaps.com/data/world-cities
- **Vers√£o Free**: 41,000 cidades
- **Dados**: city, country, lat, lon, population
- **Formato**: CSV
- **Licen√ßa**: Creative Commons

### Op√ß√£o 2: GeoNames Cities15000
- **URL**: http://download.geonames.org/export/dump/cities15000.zip
- **Cidades**: ~25,000 (popula√ß√£o >15,000)
- **Dados**: name, country, lat, lon, timezone, population
- **Formato**: TXT (tab-separated)
- **Licen√ßa**: Creative Commons

### Op√ß√£o 3: Natural Earth Data
- **URL**: https://www.naturalearthdata.com/downloads/10m-cultural-vectors/
- **Dataset**: Populated Places (10m)
- **Cidades**: ~7,500
- **Formato**: Shapefile/CSV
- **Licen√ßa**: Public Domain

**Recomenda√ß√£o**: Usar **SimpleMaps** (41k cidades) ou **GeoNames** (25k).

---

## üìä Fluxo de ETo em Tempo Real

### Quando Usu√°rio Clica no Marcador:

```python
1. Frontend envia: lat, lon (do marcador)
   ‚Üì
2. Backend busca no PostgreSQL:
   - location_name, elevation_m, timezone, preferred_climate_source
   ‚Üì
3. Backend busca dados clim√°ticos em tempo real:
   - Se preferred_climate_source = "Data Fusion":
     ‚Üí Chama m√∫ltiplas APIs (NASA + MET/NWS)
     ‚Üí Fus√£o Kalman Filter
   - Sen√£o:
     ‚Üí Chama API espec√≠fica (NASA POWER ou MET ou NWS)
   ‚Üì
4. Backend calcula ETo (Penman-Monteith):
   - Usa: temp, humidity, wind, radiation (APIs)
   - Usa: elevation_m, lat (PostgreSQL)
   ‚Üì
5. Backend retorna JSON:
   {
     "location_name": "Nagoya, Aichi, JPN",
     "latitude": 35.2,
     "longitude": 137.0,
     "elevation_m": 51.0,
     "timezone": "GMT+9.0",
     "data_source": "Data Fusion",
     "eto_mm_day": 4.3,  ‚Üê CALCULADO EM TEMPO REAL
     "climate_data": {
       "temperature_c": 25.5,
       "humidity_percent": 65,
       "wind_speed_ms": 2.3,
       ...
     }
   }
   ‚Üì
6. Frontend exibe no popup do marcador
```

**‚ö†Ô∏è IMPORTANTE**: 
- ETo √© **recalculado a cada clique**
- Dados clim√°ticos s√£o **sempre atuais** (tempo real)
- Apenas lat, lon, eleva√ß√£o v√™m do cache (PostgreSQL)

---

## üé® Frontend: Marcadores com ETo em Tempo Real

### Componente: `frontend/components/world_eto_markers.py`

```python
"""
Marcadores de localiza√ß√µes com ETo calculado em tempo real.
"""
import requests
from dash import html
import dash_leaflet as dl


def create_eto_markers():
    """
    Cria marcadores para localiza√ß√µes com ETo em tempo real.
    """
    try:
        # Buscar localiza√ß√µes do PostgreSQL
        response = requests.get(
            "http://localhost:8000/api/locations?limit=5000",
            timeout=5
        )
        locations = response.json()
        
        # Criar marcadores
        markers = []
        for loc in locations:
            marker = dl.Marker(
                id={"type": "eto-marker", "index": loc["id"]},
                position=[loc["latitude"], loc["longitude"]],
                children=[
                    dl.Tooltip(f"{loc['location_name']} - Clique para ver ETo"),
                    dl.Popup(
                        id={"type": "eto-popup", "index": loc["id"]},
                        children=html.Div([
                            html.H6(loc["location_name"]),
                            html.P("Carregando ETo...", id={"type": "eto-content", "index": loc["id"]})
                        ])
                    )
                ],
                icon=dict(
                    iconUrl="/assets/images/marker_eto.png",
                    iconSize=[25, 35]
                )
            )
            markers.append(marker)
        
        return markers
        
    except Exception as e:
        print(f"Error loading ETo markers: {e}")
        return []


# Callback para calcular ETo quando marcador √© clicado
@app.callback(
    Output({"type": "eto-content", "index": MATCH}, "children"),
    Input({"type": "eto-marker", "index": MATCH}, "n_clicks"),
    State({"type": "eto-marker", "index": MATCH}, "id"),
    prevent_initial_call=True
)
def calculate_eto_on_click(n_clicks, marker_id):
    """
    Calcula ETo em tempo real quando marcador √© clicado.
    """
    if not n_clicks:
        return "Clique para calcular ETo"
    
    location_id = marker_id["index"]
    
    try:
        # Chamar backend para calcular ETo
        response = requests.get(
            f"http://localhost:8000/api/locations/{location_id}/eto",
            timeout=10
        )
        data = response.json()
        
        return html.Div([
            html.P([
                html.Strong("üìç Eleva√ß√£o: "),
                f"{data['elevation_m']}m"
            ]),
            html.P([
                html.Strong("üïí Timezone: "),
                data['timezone']
            ]),
            html.Hr(),
            html.H5([
                html.Strong("üíß ETo: "),
                f"{data['eto_mm_day']:.2f} mm/dia"
            ], style={"color": "#2d5016"}),
            html.Hr(),
            html.P([
                html.Strong("üå°Ô∏è Temperatura: "),
                f"{data['climate_data']['temperature_c']:.1f}¬∞C"
            ], style={"fontSize": "12px"}),
            html.P([
                html.Strong("üí® Vento: "),
                f"{data['climate_data']['wind_speed_ms']:.1f} m/s"
            ], style={"fontSize": "12px"}),
            html.P([
                html.Strong("üìä Fonte: "),
                data['data_source']
            ], style={"fontSize": "11px", "fontStyle": "italic"})
        ])
        
    except Exception as e:
        return html.P(f"‚ùå Erro ao calcular ETo: {e}", style={"color": "red"})
```

---

## ‚úÖ Cronograma Atualizado

```
Semana 1: Setup e Coleta de Dados
- Dia 1: Criar modelo PostgreSQL (world_locations)
- Dia 2: Preparar CSV de entrada (SimpleMaps/GeoNames)
- Dia 3: Rodar script de download de eleva√ß√µes (5000 cidades)
- Dia 4: Importar dados para PostgreSQL

Semana 2: API Backend
- Dia 1: Endpoint GET /api/locations (listar)
- Dia 2: Endpoint GET /api/locations/{id}/eto (calcular ETo)
- Dia 3: Integrar fus√£o de dados clim√°ticos

Semana 3: Frontend
- Dia 1-2: Marcadores no mapa
- Dia 3: Callback de clique + c√°lculo ETo
- Dia 4-5: Testes e ajustes de UX

Total: ~12 dias √∫teis
```

---

## üéØ Pr√≥ximos Passos

1. ‚úÖ **Aprova√ß√£o do plano** ‚Üê Voc√™ est√° aqui
2. Baixar dataset de cidades (SimpleMaps ou GeoNames)
3. Criar modelo PostgreSQL
4. Rodar script de coleta de eleva√ß√µes
5. Implementar backend
6. Integrar frontend

**Quer que eu comece pela Fase 1 (modelo PostgreSQL + script)?** üöÄ

